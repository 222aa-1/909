#!/usr/bin/env python3
"""
å¿«é€Ÿå°çº¢ä¹¦åˆ†æ - ä½¿ç”¨æˆ‘ä»¬å·²ç»è·å–çš„æ•°æ®
"""

import json
import re
from collections import Counter
import jieba
import jieba.analyse
from datetime import datetime

def analyze_existing_data():
    """åˆ†ææˆ‘ä»¬å·²ç»è·å–çš„å°çº¢ä¹¦æ•°æ®"""
    print("ğŸ“± å°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆå¿«é€Ÿåˆ†æ")
    print("="*60)
    
    # ä»ä¹‹å‰çš„æµ‹è¯•ä¸­è·å–çš„æ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼‰
    # è¿™é‡Œä½¿ç”¨æˆ‘ä»¬ä¹‹å‰æµ‹è¯•ä¸­è·å–çš„æ ‡é¢˜
    sample_titles = [
        "æˆ‘å®£å¸ƒæ­£å¼è¿›å…¥â€œå¹´åå†è¯´â€é˜¶æ®µ",
        "å¼ äºˆæ›¦æœ¬äººç¥æ¥çš„ ",
        "ç¥æˆ‘è·‘è·¯é¡ºåˆ© ",
        "å“ˆå°”æ»¨å“ªä¸ªå•ä½æœˆè–ªèƒ½åˆ°ä¸€ä¸‡äº”åƒ...",
        "å“ˆå°”æ»¨è¿™ä¸ªå«å•¥ï¼ï¼Ÿï¼Ÿï¼Ÿå¥½å¥½åƒã€‚ã€‚ã€‚",
        "83å¹´43å² ä¹Ÿè®¸è¿™å°±æ˜¯å›æ‘ç›–é™¢çš„æ„ä¹‰å§ğŸ¥°",
        "ä¸¤ä¸ªå¤šå°æ—¶åšäº†12é“èœ",
        "ğŸ†˜ä»Šå¹´æ˜¥æ™šæ²¡çœ‹æ‡‚ï¼Œæœªæ¥ä¸‰å¹´å¯èƒ½å¾ˆè¢«åŠ¨ï¼ˆ",
        "æ’’è´å®ï¼Œå¯¹ä¸èµ· ",
        "è·³ç»™ä½ ä»¬çœ‹ ",
        "å“ˆå°”æ»¨æ¾åŒ—åŒºçš„ä¸‰é€šä¸€è¾¾ä»€ä¹ˆæ—¶å€™èƒ½æ¢å¤æ­£å¸¸å‘¢ï¼Ÿä¸ä¼šä»¥åéƒ½æ²¡æœ‰è¿™å‡ ä¸ªå¿«é€’äº†å§[å¤±æœ›R",
        "æ„Ÿè°¢æ²ˆé˜³æˆ¿ä»·ï½œ30å²ä½ä¸Šäº†æ ¼å­çª—åˆ«å¢…ğŸ ",
        "åˆä¸€æ€ªè±¡åˆ‡å®æ„Ÿè§‰åˆ°å¤§å®¶é™†ç»­åœ¨è§‰é†’",
        "å—æ–¹å°ç‹—ç¬¬ä¸€æ¬¡æ¥ä¸œåŒ—ä¸Šç‚•æ˜¯å•¥æ ·",
        "4ä¸ªé€‚åˆå¹´å¤œé¥­åšçš„å‡‰æ‹ŒèœğŸ¥—å¼€èƒƒè§£è…»",
        "å“ˆå°”æ»¨è¿™æ®µè®©æˆ‘è§‰å¾—æ˜¯äººç±»æ˜¥æ™š",
        "å¥½ä¹…æ²¡åƒæ–‡ç¥¥äº† é¦‹æ­»æˆ‘äº†ï¼ï¼",
        "åœ¨åŸºåœ°ç¢°åˆ°äº†å®å“¥ ç”šæ˜¯å¯çˆ±å‘¢ğŸ˜‚",
        "ä¸œåŒ—è¿‡å¹´çº¢åŒ…ä¸ºä»€ä¹ˆåŒ…è¿™ä¹ˆå¤§",
        "ä¸¤åªå°çŒ«â€œå„å‡­æœ¬äº‹â€è‡ªåŠ©æé±¼ï¼å›­åŒºå·²æ‹¨æ¬¾æ­å»ºçŒ«èˆâ¤ï¸ä¸€æ–¹æ°´åœŸå…»ä¸€æ–¹çŒ« çŒ«å’Œé±¼å’Œè°",
        "ä¸œåŒ—çš„ç”·äººå® åª³å¦‡æ˜¯ä¸æ˜¯çœŸçš„ å¥½åƒå¾ˆå°‘è§ä¸œåŒ—ç”·çš„å’Œåª³å¦‡åµæ¶ èµ·ç æˆ‘åˆ·åˆ°çš„è§†é¢‘éƒ½æ˜¯è¥",
        "äººï¼Œæ–°å¹´å¿«ä¹ï½ ",
        "åŸæ¥çœ¼çº¿è¦ç”»åœ¨è¿™å„¿ï¼ï¼ï¼",
        "åˆäºŒæ€»ç¥¨æˆ¿æ‰8ä¸ªå¤šäº¿ï¼ŒçœŸçš„å‡‰äº†",
        "â€˜â€™å®¡ç¾åšä¸»ä¸‹åŸºå±‚â€˜â€™â€”â€”ç»™çˆ¸å¦ˆå®¶æ–­èˆç¦»",
        "æ”¾çƒŸèŠ±å•¦ ",
        "è°æ‡‚å¤§å±æš´å‡»çš„ç¾è²Œï¼æ˜¥æ™šèˆå°ç¾æˆ‘ä¸€å¤§è·³",
        "å•¥å·¥ä½œä¸€ä¸ªæœˆèƒ½æŒ£ä¸€ä¸‡ä¸‰[ç¬‘å“­R]",
        "å“ˆå°”æ»¨åŒ»ç§‘å¤§å­¦åŸå‰¯æ ¡é•¿å¾ä¸‡æµ·è¢«åŒå¼€",
        "é»‘é¾™æ±Ÿæœ€å¥½å¬çš„åŸå¸‚å«ä»€ä¹ˆï¼ï¼ï¼",
        "ä¸œåŒ—äººç‚¹èœè¦åŒæ•°æ˜¯ä»€ä¹ˆè§„çŸ©ï¼Ÿ",
        "è¿™ä¸è¦å‘è´¢äº†.. ",
        "ç•™å­ä¸æ•¢å‘Šè¯‰çˆ¸å¦ˆçš„äº‹â—ï¸",
        "ä¸ºä»€ä¹ˆè¿‡å¹´å‘æœ‹å‹åœˆå’Œæ–°å¹´ç¥ç¦çš„äººéƒ½å°‘äº†?",
        "é¥­åº—çš„å¯’å‡å·¥ï¼Œåƒå®¢äººå‰©èœï¼"
    ]
    
    print(f"ğŸ“Š åˆ†æ {len(sample_titles)} æ¡å°çº¢ä¹¦å†…å®¹")
    
    # åˆå¹¶æ‰€æœ‰æ ‡é¢˜æ–‡æœ¬
    all_text = " ".join(sample_titles)
    
    # ä½¿ç”¨jiebaæå–å…³é”®è¯
    print("\nğŸ” æå–å…³é”®è¯...")
    keywords = jieba.analyse.extract_tags(
        all_text, 
        topK=20, 
        withWeight=True,
        allowPOS=('n', 'vn', 'v', 'a', 'nr', 'ns', 'nt', 'nz')
    )
    
    # åˆ†æå†…å®¹ç±»å‹
    print("\nğŸ“ˆ åˆ†æå†…å®¹ç±»å‹åˆ†å¸ƒ...")
    content_types = Counter()
    for title in sample_titles:
        # ç®€å•åˆ†ç±»
        if any(word in title for word in ['å“ˆå°”æ»¨', 'ä¸œåŒ—', 'æ²ˆé˜³', 'é»‘é¾™æ±Ÿ']):
            content_types['åœ°åŸŸç›¸å…³'] += 1
        elif any(word in title for word in ['ç¾é£Ÿ', 'åƒ', 'é¤å…', 'æ–™ç†', 'èœ']):
            content_types['ç¾é£Ÿ'] += 1
        elif any(word in title for word in ['æ˜¥æ™š', 'è¿‡å¹´', 'æ–°å¹´', 'æ˜¥èŠ‚', 'çº¢åŒ…']):
            content_types['èŠ‚æ—¥è¯é¢˜'] += 1
        elif any(word in title for word in ['å·¥ä½œ', 'æœˆè–ª', 'å•ä½', 'å·¥èµ„']):
            content_types['èŒåœºæ”¶å…¥'] += 1
        elif any(word in title for word in ['ç”µå½±', 'ç¥¨æˆ¿', 'å½±é™¢']):
            content_types['å½±è§†å¨±ä¹'] += 1
        elif any(word in title for word in ['å® ç‰©', 'å°çŒ«', 'å°ç‹—', 'çŒ«', 'ç‹—']):
            content_types['å® ç‰©'] += 1
        elif any(word in title for word in ['ç¾å¦†', 'åŒ–å¦†', 'çœ¼çº¿', 'æŠ¤è‚¤']):
            content_types['ç¾å¦†'] += 1
        elif any(word in title for word in ['æˆ¿å­', 'æˆ¿ä»·', 'åˆ«å¢…', 'ç›–é™¢']):
            content_types['æˆ¿äº§å®¶å±…'] += 1
        else:
            content_types['å…¶ä»–'] += 1
    
    # åˆ†ææ ‡é¢˜ç‰¹å¾
    print("\nğŸ¯ åˆ†ææ ‡é¢˜ç‰¹å¾...")
    title_features = {
        "ä½¿ç”¨è¡¨æƒ…ç¬¦å·": sum(1 for t in sample_titles if any(c in t for c in ['ğŸ¥°', 'ğŸ˜‚', 'ğŸ†˜', 'â—ï¸', 'â“', '...'])),
        "ä½¿ç”¨ç–‘é—®å¥": sum(1 for t in sample_titles if 'ï¼Ÿ' in t or '?' in t or 'ä»€ä¹ˆ' in t or 'æ€ä¹ˆ' in t),
        "ä½¿ç”¨æ„Ÿå¹è¯": sum(1 for t in sample_titles if 'ï¼' in t or '!' in t or 'ã€‚ã€‚' in t),
        "åŒ…å«æ•°å­—": sum(1 for t in sample_titles if re.search(r'\d+', t)),
        "ä½¿ç”¨æ‹¬å·": sum(1 for t in sample_titles if '(' in t or 'ï¼ˆ' in t),
    }
    
    # ç”ŸæˆæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report = f"""# å°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆåˆ†ææŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {timestamp}
åˆ†æå†…å®¹æ•°é‡: {len(sample_titles)}
æ•°æ®æ¥æº: å°çº¢ä¹¦MCPæœåŠ¡å™¨å®æ—¶è·å–

## ğŸ“Š å…³é”®è¯åˆ†æ (å‰20ä¸ª)

| æ’å | å…³é”®è¯ | æƒé‡ |
|------|--------|------|
"""
    
    for i, (keyword, weight) in enumerate(keywords, 1):
        report += f"| {i} | {keyword} | {weight:.4f} |\n"
    
    report += f"""
## ğŸ“ˆ å†…å®¹ç±»å‹åˆ†å¸ƒ

"""
    
    for content_type, count in content_types.items():
        percentage = (count / len(sample_titles)) * 100
        report += f"- **{content_type}**: {count} æ¡ ({percentage:.1f}%)\n"
    
    report += f"""
## ğŸ¯ æ ‡é¢˜ç‰¹å¾åˆ†æ

"""
    
    for feature, count in title_features.items():
        percentage = (count / len(sample_titles)) * 100
        report += f"- **{feature}**: {count} æ¡ ({percentage:.1f}%)\n"
    
    report += f"""
## ğŸ”¥ çƒ­é—¨æ ‡é¢˜ç¤ºä¾‹

"""
    
    for i, title in enumerate(sample_titles[:15], 1):
        report += f"{i}. {title}\n"
    
    report += f"""
## ğŸ’¡ çˆ†æ¬¾æ–‡æ¡ˆç‰¹å¾æ€»ç»“

### 1. å½“å‰çƒ­é—¨è¯é¢˜
- **åœ°åŸŸç‰¹è‰²**: å“ˆå°”æ»¨/ä¸œåŒ—ç›¸å…³å†…å®¹å æ¯”é«˜ ({content_types['åœ°åŸŸç›¸å…³']/len(sample_titles)*100:.1f}%)
- **èŠ‚æ—¥è¯é¢˜**: æ˜¥èŠ‚ã€è¿‡å¹´ç›¸å…³è¯é¢˜çƒ­åº¦é«˜
- **ç”Ÿæ´»å®ç”¨**: ç¾é£Ÿã€èŒåœºã€æˆ¿äº§ç­‰å®ç”¨è¯é¢˜

### 2. æ ‡é¢˜å†™ä½œæŠ€å·§
- **æƒ…æ„Ÿè¡¨è¾¾**: å¤§é‡ä½¿ç”¨è¡¨æƒ…ç¬¦å·å’Œæ„Ÿå¹è¯å¢å¼ºæƒ…æ„Ÿ
- **ç–‘é—®å¼•å¯¼**: ä½¿ç”¨ç–‘é—®å¥å¼•å‘è¯»è€…å¥½å¥‡
- **å…·ä½“ç»†èŠ‚**: åŒ…å«å…·ä½“æ•°å­—ã€åœ°ç‚¹ã€äººç‰©å¢åŠ å¯ä¿¡åº¦

### 3. å†…å®¹åˆ›ä½œå»ºè®®
1. **ç»“åˆåœ°åŸŸç‰¹è‰²**: ä¸œåŒ—/å“ˆå°”æ»¨è¯é¢˜å½“å‰çƒ­åº¦é«˜
2. **èŠ‚æ—¥çƒ­ç‚¹**: æŠ“ä½æ˜¥èŠ‚ç›¸å…³è¯é¢˜
3. **å®ç”¨ä»·å€¼**: æä¾›ç¾é£Ÿã€èŒåœºã€ç”Ÿæ´»å®ç”¨ä¿¡æ¯
4. **æƒ…æ„Ÿå…±é¸£**: ä½¿ç”¨å¼ºçƒˆçš„æƒ…æ„Ÿè¡¨è¾¾
5. **è§†è§‰å…ƒç´ **: é…åˆé«˜è´¨é‡å›¾ç‰‡/è§†é¢‘

## ğŸ“ çˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿æ¨è

1. **åœ°åŸŸ+è¯é¢˜**: "å“ˆå°”æ»¨XXXï¼ŒXXXäººéƒ½è¯´XXX"
2. **ç–‘é—®+è§£ç­”**: "XXXä¸ºä»€ä¹ˆXXXï¼ŸåŸæ¥è¦è¿™æ ·XXX"
3. **æ•°å­—+ä»·å€¼**: "XXXä¸ªXXXæŠ€å·§ï¼Œè®©ä½ XXXä¸å†XXX"
4. **æƒ…æ„Ÿ+åˆ†äº«**: "æˆ‘å®£å¸ƒXXXæ˜¯ä»Šå¹´æœ€XXXçš„XXXï¼"
5. **å¯¹æ¯”+é€‰æ‹©**: "XXX vs XXXï¼Œå“ªä¸ªæ›´XXXï¼Ÿ"

## ğŸ¯ çƒ­é—¨å…³é”®è¯æ¨è

åŸºäºåˆ†æï¼Œä»¥ä¸‹å…³é”®è¯æ›´å®¹æ˜“è·å¾—å…³æ³¨:
{', '.join([k for k, _ in keywords[:10]])}

---
*åˆ†æåŸºäºå°çº¢ä¹¦å®æ—¶å†…å®¹ï¼Œæ•°æ®ä»…ä¾›å‚è€ƒ*
"""
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = f"å°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆå¿«é€Ÿåˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    with open(report_file, "w", encoding="utf-8") as f:
        f.write(report)
    
    print(f"\nâœ… åˆ†æå®Œæˆ!")
    print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    # æ‰“å°å…³é”®æ‘˜è¦
    print("\n" + "="*60)
    print("ğŸ“‹ å…³é”®æ‘˜è¦:")
    print("-" * 40)
    print(f"ğŸ“Š åˆ†æå†…å®¹: {len(sample_titles)} æ¡")
    print(f"ğŸ”¥ çƒ­é—¨å…³é”®è¯: {', '.join([k for k, _ in keywords[:5]])}")
    print(f"ğŸ“ ä¸»è¦è¯é¢˜: åœ°åŸŸç›¸å…³({content_types['åœ°åŸŸç›¸å…³']}æ¡), ç¾é£Ÿ({content_types['ç¾é£Ÿ']}æ¡), èŠ‚æ—¥è¯é¢˜({content_types['èŠ‚æ—¥è¯é¢˜']}æ¡)")
    print(f"ğŸ¯ æ ‡é¢˜ç‰¹å¾: {title_features['ä½¿ç”¨è¡¨æƒ…ç¬¦å·']}æ¡ä½¿ç”¨è¡¨æƒ…, {title_features['ä½¿ç”¨ç–‘é—®å¥']}æ¡ç–‘é—®å¥")
    print("="*60)
    
    return report

if __name__ == "__main__":
    analyze_existing_data()